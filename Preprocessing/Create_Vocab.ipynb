{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Create_Vocab.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPPWIpK+eoh1ECC9m+GY3HT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HpdfWeqJlcmg","executionInfo":{"status":"ok","timestamp":1618884159084,"user_tz":240,"elapsed":1426,"user":{"displayName":"Justin Chen","photoUrl":"","userId":"17694757636074260730"}},"outputId":"99b9de01-8ef8-41e3-d289-3854a6147d58"},"source":["import os\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","os.chdir(\"drive/MyDrive/Colab Notebooks/CS7650/final\")\n","os.listdir()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["['data',\n"," 'resiyrces.gdoc',\n"," 'NBOW.ipynb',\n"," 'Naive_Bayes.ipynb',\n"," 'Clean_Data.ipynb',\n"," 'Create_Vocab.ipynb']"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"m9lDijtPj2bB"},"source":["from collections import Counter\n","import pandas as pd\n","import numpy as np\n","import csv\n","import json"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":197},"id":"_C6xMb5dloD-","executionInfo":{"status":"ok","timestamp":1618884160959,"user_tz":240,"elapsed":3290,"user":{"displayName":"Justin Chen","photoUrl":"","userId":"17694757636074260730"}},"outputId":"5627ca82-36f2-4515-876b-5d58bd536562"},"source":["df = pd.read_csv('data/train_clean.csv')\n","df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>id</th>\n","      <th>comment_text</th>\n","      <th>toxic</th>\n","      <th>severe_toxic</th>\n","      <th>obscene</th>\n","      <th>threat</th>\n","      <th>insult</th>\n","      <th>identity_hate</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0000997932d777bf</td>\n","      <td>explanation why the edits made under my userna...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>000103f0d9cfb60f</td>\n","      <td>daww he matches this background colour im seem...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>000113f07ec002fd</td>\n","      <td>hey man im really not trying to edit war its j...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>0001b41b1c6bb37e</td>\n","      <td>more i cant make any real suggestions on impro...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>0001d958c54c6e35</td>\n","      <td>you sir are my hero any chance you remember wh...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0                id  ... insult  identity_hate\n","0           0  0000997932d777bf  ...      0              0\n","1           1  000103f0d9cfb60f  ...      0              0\n","2           2  000113f07ec002fd  ...      0              0\n","3           3  0001b41b1c6bb37e  ...      0              0\n","4           4  0001d958c54c6e35  ...      0              0\n","\n","[5 rows x 9 columns]"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"8krKfirzljGQ"},"source":["class Vocab:\n","  def __init__(self, comments, min_count=0):\n","    self.num_words = 1\n","    self.word2id = {'UNK': 0}\n","    self.word_counts = Counter()\n","    self.min_count = min_count\n","\n","    comments.str.split().apply(self.word_counts.update)\n","    for word in list(self.word_counts.keys()):\n","      if self.word_counts[word] > self.min_count:\n","        self.word2id[word] = self.num_words\n","        self.num_words += 1\n","    self.vocab = list(self.word2id.keys())\n","  \n","  def sentence2indices(self, sentences):\n","    return [[self.word2id.get(word, 0) for word in s] for s in sentences]\n","  \n","  def save_vocab(self):\n","    with open('data/vocab/word2id.json', 'w') as file:\n","      json.dump(self.word2id, file)\n","      file.close()\n","    with open('data/vocab/word_counts.json', 'w') as file:\n","      json.dump(self.word_counts, file)\n","      file.close()\n","    with open('data/vocab.json', 'w') as file:\n","      json.dump(self.vocab, file)\n","      file.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1rPk-PHomvOe"},"source":["V = Vocab(df['comment_text'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sQ-Hx6CPo92k"},"source":["V.save_vocab()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dHo_n9ljs0bO"},"source":["# def filter_glove(File, vocab):\n","#   print(\"Loading Glove Model\")\n","#   f = open(File,'r')\n","#   gloveModel = {}\n","#   for line in f:\n","#     splitLines = line.split()\n","#     word = splitLines[0]\n","#     if word in vocab:\n","#       wordEmbedding = np.array([float(value) for value in splitLines[1:]])\n","#       gloveModel[word] = wordEmbedding\n","#   print(len(gloveModel),\" words loaded!\")\n","#   return gloveModel\n","def filter_glove(file, vocab):\n","  print('Loading gloVe')\n","  df = pd.read_table(file, sep=\" \", index_col=0, header=None, quoting=csv.QUOTE_NONE)\n","  print(df.shape)\n","  print('filtering glove')\n","  df = df[df.index.isin(vocab)]\n","  print(df.shape)\n","  print('sending to dict')\n","  #glove = {key: val.values for key, val in df.T.items() if key in vocab}\n","  glove = {key: val.values.tolist() for key, val in df.T.items()}\n","  return glove"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YWy4AwKdtAZ1","executionInfo":{"status":"ok","timestamp":1618884252275,"user_tz":240,"elapsed":94582,"user":{"displayName":"Justin Chen","photoUrl":"","userId":"17694757636074260730"}},"outputId":"05c9d207-7715-4b51-a374-5686566ed541"},"source":["glove = filter_glove('data/gloVe/glove.6B.300d.txt', V.vocab)\n","with open('data/gloVe/filtered_glove.json', 'w') as file:\n","  json.dump(glove, file)\n","  file.close()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Loading gloVe\n","(400000, 300)\n","filtering glove\n","(93979, 300)\n","sending to dict\n"],"name":"stdout"}]}]}